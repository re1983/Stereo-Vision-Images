{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('Data\\Videos\\wymont.MOV')\n",
    "\n",
    "# Take first frame and convert it to grayscale\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow between two frames\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs,next,None,0.5,3,15,3,5,1.2,0)\n",
    "\n",
    "    # Convert optical flow to polar coordinates\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "\n",
    "    # Set image hue according to the optical flow direction\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "\n",
    "    # Set image value according to the optical flow magnitude (normalized)\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "\n",
    "    # Convert HSV to BGR\n",
    "    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "\n",
    "    cv.imshow('frame2',bgr)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update previous frame\n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "img1 = cv.imread('img1.jpg')\n",
    "img2 = cv.imread('img2.jpg')\n",
    "\n",
    "# Convert images to grayscale\n",
    "gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect keypoints and compute descriptors using SIFT\n",
    "sift = cv.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "# Match keypoints using FLANN matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Filter matches using Lowe's ratio test\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Estimate fundamental matrix using RANSAC\n",
    "pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "F, mask = cv.findFundamentalMat(pts1, pts2, cv.FM_RANSAC)\n",
    "\n",
    "# Estimate essential matrix from fundamental matrix and camera intrinsics\n",
    "K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "E = K.T @ F @ K\n",
    "\n",
    "# Decompose essential matrix into rotation and translation matrices\n",
    "retval, R1, t1, R2, t2 = cv.decomposeEssentialMat(E)\n",
    "\n",
    "# Triangulate points using the first camera matrix and the second camera matrix\n",
    "P1 = np.array([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.]])\n",
    "P2_1 = K @ np.hstack((R1,t1))\n",
    "P2_2 = K @ np.hstack((R1,t2))\n",
    "P2_3 = K @ np.hstack((R2,t1))\n",
    "P2_4 = K @ np.hstack((R2,t2))\n",
    "points4D_1 = cv.triangulatePoints(P1,P2_1,pts1.T[:3],pts2.T[:3])\n",
    "points4D_2 = cv.triangulatePoints(P1,P2_2,pts1.T[:3],pts2.T[:3])\n",
    "points4D_3 = cv.triangulatePoints(P1,P2_3,pts1.T[:3],pts2.T[:3])\n",
    "points4D_4 = cv.triangulatePoints(P1,P2_4,pts1.T[:3],pts2.T[:3])\n",
    "\n",
    "# Convert homogeneous coordinates to Euclidean coordinates\n",
    "points3D_1 = points4D_1[:3]/points4D_1[3]\n",
    "points3D_2 = points4D_2[:3]/points4D_2[3]\n",
    "points3D_3 = points4D_3[:3]/points4D_3[3]\n",
    "points3D_4 = points4D_4[:3]/points4D_4[3]\n",
    "\n",
    "print(points3D_1)\n",
    "print(points3D_2)\n",
    "print(points3D_3)\n",
    "print(points3D_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv.imread('img.jpg')\n",
    "\n",
    "# Create mask\n",
    "mask = np.zeros_like(img[:,:,0])\n",
    "mask[100:200, 100:200] = 255\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect corners using goodFeaturesToTrack with mask\n",
    "corners = cv.goodFeaturesToTrack(gray, 100, 0.01, 10, mask=mask)\n",
    "\n",
    "# Draw corners on image\n",
    "for corner in corners:\n",
    "    x,y = corner.ravel()\n",
    "    cv.circle(img,(x,y),3,(0,255,0),-1)\n",
    "\n",
    "# Display image\n",
    "cv.imshow('image', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
