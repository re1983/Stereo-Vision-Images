{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import cv2\n",
    "#Structural Similarity Index\n",
    "def SSIM_two_images(img1, img2): \n",
    "    gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ssim_value = ssim(gray_img1, gray_img2)\n",
    "\n",
    "    # if ssim_value == 1:\n",
    "    #     print(\"SSIM: The images are identical\")\n",
    "    # else:\n",
    "    #     print(\"SSIM: The images are not identical\")\n",
    "    return ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "def  MSE_two_images(img1, img2):\n",
    "    # gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    # gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    mse = ((img1 - img2) ** 2).mean(axis=None)\n",
    "\n",
    "    # if mse == 0:\n",
    "    #     print(\"MSE: The images are identical\")\n",
    "    # else:\n",
    "    #     print(\"MSE: The images are not identical\")\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def To_got_goodFeaturesToTrack(image):\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Applying the function\n",
    "    corners = cv2.goodFeaturesToTrack(\n",
    "        gray_image, maxCorners=8192, qualityLevel=0.04, minDistance=9, blockSize=9)\n",
    "    corners = np.float32(corners)\n",
    "    # print(len(corners))\n",
    "    for item in corners:\n",
    "        x, y = item[0]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        cv2.circle(image, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    return image\n",
    "    # RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Pyramid Lucas-Kanade optical flow\n",
    "def To_got_optical_flow(image1, image2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "Height of Image: 1080 pixels\n",
      "Width of Image:  1920 pixels\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# vidcap = cv2.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\n",
    "vidcap = cv2.VideoCapture('Data\\Videos\\wymont.MOV')\n",
    "success,image = vidcap.read()\n",
    "print(image.shape) \n",
    "print('Height of Image:', int(image.shape[0]), 'pixels')\n",
    "print('Width of Image: ', int(image.shape[1]), 'pixels')\n",
    "count = 0\n",
    "old_image = image\n",
    "while success:\n",
    "\n",
    "    #cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "    cv2.imshow('image', To_got_goodFeaturesToTrack(image))      # show frame\n",
    "    # print('MSE: ', MSE_two_images(image, old_image)) # compare two images\n",
    "    # print('SSIM: ', SSIM_two_images(image, old_image)) # compare two images\n",
    "    # gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    old_image = image\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:         # wait for ESC key to exit\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    success,image = vidcap.read()   # read next frame\n",
    "    # print('Read a new frame: ', success, count)\n",
    "    count += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vidcap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sandipanweb.wordpress.com/2018/02/25/implementing-lucas-kanade-optical-flow-algorithm-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to calculate the frame rate with python opencv\n",
    "# https://www.geeksforgeeks.org/how-to-calculate-the-frame-rate-with-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "cap = cv.VideoCapture('Data\\Videos\\wymont.MOV')\n",
    "# cap = cv.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\n",
    "#角点检测参数\n",
    "# feature_params = dict(maxCorners=128, qualityLevel=0.1, minDistance=7, blockSize=7)\n",
    "feature_params = dict(maxCorners=512, qualityLevel=0.04, minDistance=9, blockSize=9)\n",
    "\n",
    "\n",
    "#KLT光流参数\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.02))\n",
    "\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "#out = cv.VideoWriter(\"reslut.avi\", cv.VideoWriter_fourcc('D', 'I', 'V', 'X'), fps,\n",
    "                     #(np.int(width), np.int(height)), True)\n",
    "\n",
    "tracks = []\n",
    "track_len = 10\n",
    "frame_idx = 0\n",
    "detect_interval = 10\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        vis = frame.copy()\n",
    "\n",
    "        if len(tracks)>0:\n",
    "            img0 ,img1 = prev_gray, frame_gray\n",
    "            p0 = np.float32([tr[-1] for tr in tracks]).reshape(-1,1,2)\n",
    "            # 上一帧的角点和当前帧的图像作为输入来得到角点在当前帧的位置  \n",
    "            p1, st, err = cv.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "\n",
    "            # 反向检查,当前帧跟踪到的角点及图像和前一帧的图像作为输入来找到前一帧的角点位置  \n",
    "            p0r, _, _ = cv.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "\n",
    "            # 得到角点回溯与前一帧实际角点的位置变化关系 \n",
    "            d = abs(p0-p0r).reshape(-1,2).max(-1)\n",
    "\n",
    "            #判断d内的值是否小于1，大于1跟踪被认为是错误的跟踪点\n",
    "            good = d < 1\n",
    "\n",
    "            new_tracks = []\n",
    "\n",
    "            for i, (tr, (x, y), flag) in enumerate(zip(tracks, p1.reshape(-1, 2), good)):\n",
    "\n",
    "                # 判断是否为正确的跟踪点\n",
    "                if not flag:\n",
    "                    continue\n",
    "\n",
    "                # 存储动态的角点\n",
    "                tr.append((x, y))\n",
    "\n",
    "                # 只保留track_len长度的数据，消除掉前面的超出的轨迹\n",
    "                if len(tr) > track_len:\n",
    "                    del tr[0]\n",
    "                # 保存在新的list中\n",
    "                new_tracks.append(tr)\n",
    "\n",
    "                # cv.circle(vis, (x, y), 2, (0, 255, 0), -1)\n",
    "                cv.circle(vis, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "            # 更新特征点    \n",
    "            tracks = new_tracks\n",
    "\n",
    "            # #以上一振角点为初始点，当前帧跟踪到的点为终点,画出运动轨迹\n",
    "            cv.polylines(vis, [np.int32(tr) for tr in tracks], False, (0, 0, 255), 1)\n",
    "            # cv.circle(vis, [np.int32(tr) for tr in tracks], False, (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "        # 每隔 detect_interval 时间检测一次特征点\n",
    "        if frame_idx % detect_interval==0:\n",
    "            # mask = np.zeros_like(frame_gray)\n",
    "            # mask[:] = 255\n",
    "\n",
    "            # if frame_idx !=0:\n",
    "            #     for x,y in [np.int32(tr[-1]) for tr in tracks]:\n",
    "            #         cv.circle(mask, (x, y), 5, 0, -1)\n",
    "\n",
    "            # p = cv.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
    "            p = cv.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "            if p is not None:\n",
    "                for x, y in np.float32(p).reshape(-1,2):\n",
    "                    tracks.append([(x, y)])\n",
    "\n",
    "        frame_idx += 1\n",
    "        prev_gray = frame_gray\n",
    "\n",
    "        cv.imshow('track', vis)\n",
    "        #out.write(vis)\n",
    "        ch = cv.waitKey(1)\n",
    "        if ch ==27:\n",
    "            # cv.imwrite('track.jpg', vis)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='This sample demonstrates Lucas-Kanade Optical Flow calculation. \\\n",
    "#                                               The example file can be downloaded from: \\\n",
    "#                                               https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')\n",
    "# parser.add_argument('image', type=str, help='path to image file')\n",
    "# args = parser.parse_args()\n",
    "# cap = cv.VideoCapture(args.image)\n",
    "# cap = cv.VideoCapture('Data\\Videos\\wymont.MOV')\n",
    "cap = cv.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "    img = cv.add(frame, mask)\n",
    "\n",
    "    cv.imshow('frame', img)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(\"Data\\Videos\\wymont.MOV\")\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "\n",
    "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    cv.imshow('frame2', bgr)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv.imwrite('opticalfb.png', frame2)\n",
    "        cv.imwrite('opticalhsv.png', bgr)\n",
    "    prvs = next\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
