{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "cap = cv.VideoCapture('Data/Videos/wymont.MOV')\n",
    "# cap = cv.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\n",
    "#角点检测参数\n",
    "# feature_params = dict(maxCorners=128, qualityLevel=0.1, minDistance=7, blockSize=7)\n",
    "feature_params = dict(maxCorners=1024, qualityLevel=0.04, minDistance=9, blockSize=9)\n",
    "\n",
    "\n",
    "#KLT光流参数\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.02))\n",
    "\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "#out = cv.VideoWriter(\"reslut.avi\", cv.VideoWriter_fourcc('D', 'I', 'V', 'X'), fps,\n",
    "                     #(np.int(width), np.int(height)), True)\n",
    "\n",
    "tracks = []\n",
    "track_len = 30\n",
    "frame_idx = 0\n",
    "detect_interval = 10\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        vis = frame.copy()\n",
    "\n",
    "        if len(tracks)>0:\n",
    "            img0 ,img1 = prev_gray, frame_gray\n",
    "            p0 = np.float32([tr[-1] for tr in tracks]).reshape(-1,1,2)\n",
    "            # 上一帧的角点和当前帧的图像作为输入来得到角点在当前帧的位置  \n",
    "            p1, st, err = cv.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "\n",
    "            # 反向检查,当前帧跟踪到的角点及图像和前一帧的图像作为输入来找到前一帧的角点位置  \n",
    "            p0r, _, _ = cv.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "\n",
    "            # 得到角点回溯与前一帧实际角点的位置变化关系 \n",
    "            d = abs(p0-p0r).reshape(-1,2).max(-1)\n",
    "\n",
    "            #判断d内的值是否小于1，大于1跟踪被认为是错误的跟踪点\n",
    "            good = d < 1\n",
    "\n",
    "            new_tracks = []\n",
    "\n",
    "            for i, (tr, (x, y), flag) in enumerate(zip(tracks, p1.reshape(-1, 2), good)):\n",
    "\n",
    "                # 判断是否为正确的跟踪点\n",
    "                if not flag:\n",
    "                    continue\n",
    "\n",
    "                # 存储动态的角点\n",
    "                tr.append((x, y))\n",
    "\n",
    "                # 只保留track_len长度的数据，消除掉前面的超出的轨迹\n",
    "                if len(tr) > track_len:\n",
    "                    del tr[0]\n",
    "                # 保存在新的list中\n",
    "                new_tracks.append(tr)\n",
    "\n",
    "                # cv.circle(vis, (x, y), 2, (0, 255, 0), -1)\n",
    "                cv.circle(vis, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "            # 更新特征点    \n",
    "            tracks = new_tracks\n",
    "\n",
    "            # #以上一振角点为初始点，当前帧跟踪到的点为终点,画出运动轨迹\n",
    "            cv.polylines(vis, [np.int32(tr) for tr in tracks], False, (0, 0, 255), 1)\n",
    "            # cv.circle(vis, [np.int32(tr) for tr in tracks], False, (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "        # 每隔 detect_interval 时间检测一次特征点\n",
    "        if frame_idx % detect_interval==0:\n",
    "            # mask = np.zeros_like(frame_gray)\n",
    "            # mask[:] = 255\n",
    "\n",
    "            # if frame_idx !=0:\n",
    "            #     for x,y in [np.int32(tr[-1]) for tr in tracks]:\n",
    "            #         cv.circle(mask, (x, y), 5, 0, -1)\n",
    "\n",
    "            # p = cv.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
    "            p = cv.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "            if p is not None:\n",
    "                for x, y in np.float32(p).reshape(-1,2):\n",
    "                    tracks.append([(x, y)])\n",
    "\n",
    "        frame_idx += 1\n",
    "        prev_gray = frame_gray\n",
    "\n",
    "        cv.imshow('track', vis)\n",
    "        #out.write(vis)\n",
    "        ch = cv.waitKey(1)\n",
    "        if ch ==27:\n",
    "            # cv.imwrite('track.jpg', vis)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://amroamroamro.github.io/mexopencv/opencv/lk_homography_demo.html#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m cap \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mVideoCapture(\u001b[39m'\u001b[39m\u001b[39mData/Videos/wymont.MOV\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# cap = cv.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m lk_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m( winSize  \u001b[39m=\u001b[39m (\u001b[39m19\u001b[39m, \u001b[39m19\u001b[39m),\n\u001b[1;32m      8\u001b[0m                   maxLevel \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m----> 9\u001b[0m                   criteria \u001b[39m=\u001b[39m (cv2\u001b[39m.\u001b[39mTERM_CRITERIA_EPS \u001b[39m|\u001b[39m cv2\u001b[39m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[39m10\u001b[39m, \u001b[39m0.03\u001b[39m))\n\u001b[1;32m     11\u001b[0m feature_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m( maxCorners \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m     12\u001b[0m                        qualityLevel \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m,\n\u001b[1;32m     13\u001b[0m                        minDistance \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m,\n\u001b[1;32m     14\u001b[0m                        blockSize \u001b[39m=\u001b[39m \u001b[39m19\u001b[39m )\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheckedTrace\u001b[39m(img0, img1, p0, back_threshold \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "cap = cv.VideoCapture('Data/Videos/wymont.MOV')\n",
    "# cap = cv.VideoCapture('Data\\Videos\\Aerial View of the Great Pyramid of Giza.mp4')\n",
    "\n",
    "lk_params = dict( winSize  = (19, 19),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "feature_params = dict( maxCorners = 0,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 8,\n",
    "                       blockSize = 19 )\n",
    "\n",
    "\n",
    "def checkedTrace(img0, img1, p0, back_threshold = 1.0):\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "    p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "    d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "    status = d < back_threshold\n",
    "    return p1, status\n",
    "\n",
    "\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "#out = cv.VideoWriter(\"reslut.avi\", cv.VideoWriter_fourcc('D', 'I', 'V', 'X'), fps,\n",
    "                     #(np.int(width), np.int(height)), True)\n",
    "\n",
    "tracks = []\n",
    "track_len = 30\n",
    "frame_idx = 0\n",
    "detect_interval = 500\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        vis = frame.copy()\n",
    "\n",
    "        if len(tracks)>0:\n",
    "            img0 ,img1 = prev_gray, frame_gray\n",
    "            p0 = np.float32([tr[-1] for tr in tracks]).reshape(-1,1,2)\n",
    "            # 上一帧的角点和当前帧的图像作为输入来得到角点在当前帧的位置  \n",
    "            p1, st, err = cv.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "\n",
    "            # 反向检查,当前帧跟踪到的角点及图像和前一帧的图像作为输入来找到前一帧的角点位置  \n",
    "            p0r, _, _ = cv.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "\n",
    "            # 得到角点回溯与前一帧实际角点的位置变化关系 \n",
    "            d = abs(p0-p0r).reshape(-1,2).max(-1)\n",
    "\n",
    "            #判断d内的值是否小于1，大于1跟踪被认为是错误的跟踪点\n",
    "            good = d < 1\n",
    "\n",
    "            new_tracks = []\n",
    "\n",
    "            for i, (tr, (x, y), flag) in enumerate(zip(tracks, p1.reshape(-1, 2), good)):\n",
    "\n",
    "                # 判断是否为正确的跟踪点\n",
    "                if not flag:\n",
    "                    continue\n",
    "\n",
    "                # 存储动态的角点\n",
    "                tr.append((x, y))\n",
    "\n",
    "                # 只保留track_len长度的数据，消除掉前面的超出的轨迹\n",
    "                if len(tr) > track_len:\n",
    "                    del tr[0]\n",
    "                # 保存在新的list中\n",
    "                new_tracks.append(tr)\n",
    "\n",
    "                # cv.circle(vis, (x, y), 2, (0, 255, 0), -1)\n",
    "                cv.circle(vis, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "            # 更新特征点    \n",
    "            tracks = new_tracks\n",
    "\n",
    "            # #以上一振角点为初始点，当前帧跟踪到的点为终点,画出运动轨迹\n",
    "            # cv.polylines(vis, [np.int32(tr) for tr in tracks], False, (0, 0, 255), 1)\n",
    "            # cv.circle(vis, [np.int32(tr) for tr in tracks], False, (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "        # 每隔 detect_interval 时间检测一次特征点\n",
    "        if frame_idx % detect_interval==0:\n",
    "            # mask = np.zeros_like(frame_gray)\n",
    "            # mask[:] = 255\n",
    "\n",
    "            # if frame_idx !=0:\n",
    "            #     for x,y in [np.int32(tr[-1]) for tr in tracks]:\n",
    "            #         cv.circle(mask, (x, y), 5, 0, -1)\n",
    "\n",
    "            # p = cv.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
    "            p = cv.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "            if p is not None:\n",
    "                for x, y in np.float32(p).reshape(-1,2):\n",
    "                    tracks.append([(x, y)])\n",
    "\n",
    "        frame_idx += 1\n",
    "        prev_gray = frame_gray\n",
    "\n",
    "        cv.imshow('track', vis)\n",
    "        #out.write(vis)\n",
    "        ch = cv.waitKey(1)\n",
    "        if ch ==27:\n",
    "            # cv.imwrite('track.jpg', vis)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lucas-Kanade homography tracker\n",
      "===============================\n",
      "\n",
      "Lucas-Kanade sparse optical flow demo. Uses goodFeaturesToTrack\n",
      "for track initialization and back-tracking for match verification\n",
      "between frames. Finds homography between reference and current views.\n",
      "\n",
      "Usage\n",
      "-----\n",
      "lk_homography.py [<video_source>]\n",
      "\n",
      "\n",
      "Keys\n",
      "----\n",
      "ESC   - exit\n",
      "SPACE - start tracking\n",
      "r     - toggle RANSAC\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'App' object has no attribute 'gray1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m     cap\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 136\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[4], line 131\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m     video_src \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m__doc__\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m App(video_src)\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    132\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    133\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "Cell \u001b[0;32mIn[4], line 71\u001b[0m, in \u001b[0;36mApp.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m# print(self.p0)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp0 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     p2, trace_status \u001b[39m=\u001b[39m checkedTrace(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgray1, frame_gray, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp1)\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp1 \u001b[39m=\u001b[39m p2[trace_status]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp0[trace_status]\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'App' object has no attribute 'gray1'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "Lucas-Kanade homography tracker\n",
    "===============================\n",
    "\n",
    "Lucas-Kanade sparse optical flow demo. Uses goodFeaturesToTrack\n",
    "for track initialization and back-tracking for match verification\n",
    "between frames. Finds homography between reference and current views.\n",
    "\n",
    "Usage\n",
    "-----\n",
    "lk_homography.py [<video_source>]\n",
    "\n",
    "\n",
    "Keys\n",
    "----\n",
    "ESC   - exit\n",
    "SPACE - start tracking\n",
    "r     - toggle RANSAC\n",
    "'''\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import video\n",
    "from common import draw_str\n",
    "# from video import presets\n",
    "\n",
    "lk_params = dict( winSize  = (19, 19),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "feature_params = dict( maxCorners = 0,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 8,\n",
    "                       blockSize = 19 )\n",
    "\n",
    "def checkedTrace(img0, img1, p0, back_threshold = 1.0):\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "    p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "    d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "    status = d < back_threshold\n",
    "    return p1, status\n",
    "\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "\n",
    "class App:\n",
    "    def __init__(self, video_src):\n",
    "        # self.cam = self.cam = video.create_capture(video_src, presets['book']) #cap = cv.VideoCapture('Data/Videos/wymont.MOV')\n",
    "        self.cam = self.cam = cv2.VideoCapture('Data/Videos/wymont.MOV')\n",
    "        self.p0 = None\n",
    "        self.use_ransac = True\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            ret, frame = self.cam.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            frame = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            vis = frame.copy()\n",
    "\n",
    "            self.p0 = cv2.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "\n",
    "            # print(self.p0)\n",
    "            if self.p0 is not None:\n",
    "                p2, trace_status = checkedTrace(self.gray1, frame_gray, self.p1)\n",
    "\n",
    "                self.p1 = p2[trace_status].copy()\n",
    "                self.p0 = self.p0[trace_status].copy()\n",
    "                self.gray1 = frame_gray\n",
    "\n",
    "                if len(self.p0) < 4:\n",
    "                    self.p0 = None\n",
    "                    continue\n",
    "                H, status = cv2.findHomography(self.p0, self.p1, cv2.RANSAC, 0.03)\n",
    "                h, w = frame.shape[:2]\n",
    "                overlay = cv2.warpPerspective(self.frame0, H, (w, h))\n",
    "                vis = cv2.addWeighted(vis, 0.5, overlay, 0.5, 0.0)\n",
    "\n",
    "                for (x0, y0), (x1, y1), good in zip(self.p0[:,0], self.p1[:,0], status[:,0]):\n",
    "                    if good:\n",
    "                        cv2.line(vis, (x0, y0), (x1, y1), (0, 128, 0))\n",
    "                    cv2.circle(vis, (x1, y1), 5, (red, green)[good], 1)\n",
    "                draw_str(vis, (20, 20), 'track count: %d' % len(self.p1))\n",
    "                if self.use_ransac:\n",
    "                    draw_str(vis, (20, 40), 'RANSAC')\n",
    "            else:\n",
    "                p = cv2.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "                if p is not None:\n",
    "                    for x, y in p[:,0]:\n",
    "                        cv2.circle(vis, (int(x), int(y)), 2, green, -1)\n",
    "                    draw_str(vis, (20, 20), 'feature count: %d' % len(p))\n",
    "\n",
    "            cv2.imshow('lk_homography', vis)\n",
    "\n",
    "            ch = cv2.waitKey(0)\n",
    "            if ch == 27:\n",
    "                break\n",
    "            # if ch == ord(' '):\n",
    "            #     self.frame0 = frame.copy()\n",
    "            #     self.p0 = cv2.goodFeaturesToTrack(frame_gray, **feature_params)\n",
    "            #     if self.p0 is not None:\n",
    "            #         self.p1 = self.p0\n",
    "            #         self.gray0 = frame_gray\n",
    "            #         self.gray1 = frame_gray\n",
    "\n",
    "            # if ch == ord('r'):\n",
    "            #     self.use_ransac = not self.use_ransac\n",
    "            \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# App().run()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    import sys\n",
    "    try:\n",
    "        video_src = sys.argv[1]\n",
    "    except:\n",
    "        video_src = 0\n",
    "\n",
    "    print(__doc__)\n",
    "    App(video_src).run()\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
